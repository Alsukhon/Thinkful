{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal from this assignment is to make 5 classifier versions and see which performs best. The time it takes to prepare each model, the time it takes to run it, and the accuracy all count towards the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 185\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "amazon = pd.read_csv(r'amazon_cells_labelled.txt', delimiter= '\\t', header=None)\n",
    "amazon.columns = ['text', 'sentiment']\n",
    "\n",
    "# load positive & negative word corpora\n",
    "positive, negative = [open(file,'r').read() for file in ['positive-words.txt','negative-words.txt']]\n",
    "\n",
    "# remove description and make it a list\n",
    "positive, negative = [corpus[corpus.rfind(';')+1:] for corpus in [positive, negative]]\n",
    "positive, negative = [corpus.split('\\n') for corpus in [positive, negative]]\n",
    "\n",
    "# Remove whitespace characters\n",
    "for corpus in [positive, negative]:\n",
    "    for i in range(corpus.count('')):\n",
    "        corpus.remove('')    \n",
    "\n",
    "# add a couple of positive words    \n",
    "positive.append('cool')\n",
    "positive.append('decent')\n",
    "    \n",
    "# load list of stop words\n",
    "with open('stop_words.txt','r') as file:\n",
    "    stop = file.read()\n",
    "stop = stop.split('\\n')\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuation(word):\n",
    "    \"\"\" removes punctuation from a word\"\"\"\n",
    "    \n",
    "    punctuation = ''.join(['.',',',';',':','-','?','!','*'])\n",
    "    TRANSDICT = str.maketrans(punctuation,' '*len(punctuation))\n",
    "    return word.translate(TRANSDICT).strip().replace(' ','').replace('* ','')\n",
    "\n",
    "\n",
    "def percent_positive(review):\n",
    "    \"\"\" Tokenizes each sentence, checks for membership in positive words,\n",
    "        makes sure positive words are not preceded by 'not'\n",
    "    \"\"\"\n",
    "    \n",
    "    # tokenize a sentence and remove punctuation\n",
    "    tokenized = review.lower().split(' ')\n",
    "    tokenized = [remove_punctuation(word) for word in tokenized]\n",
    "    pcnt = 0\n",
    "    \n",
    "    # check for membership in poitive words list, making sure 'not' doesn't precede\n",
    "    for word in tokenized:\n",
    "        if tokenized.index(word) == 0 and (word in positive):\n",
    "            pcnt += 1/len(tokenized)\n",
    "        elif tokenized.index(word) == 1:\n",
    "            if word in positive and (tokenized[tokenized.index(word)-1] != 'not'):\n",
    "                pcnt += 1/len(tokenized)\n",
    "        elif tokenized.index(word) > 1:\n",
    "            if word in positive and (tokenized[tokenized.index(word)-1] != 'not') and (tokenized[tokenized.index(word)-2] != 'not'):\n",
    "                pcnt += 1/len(tokenized)\n",
    "    return pcnt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def percent_negative(review):\n",
    "    \"\"\" Tokenizes each sentence, checks for membership in positive words,\n",
    "        makes sure positive words are not perceded by 'not'\n",
    "    \"\"\"\n",
    "    \n",
    "    # tokenize a sentence and remove punctuation\n",
    "    tokenized = review.lower().split(' ')\n",
    "    tokenized = [remove_punctuation(word) for word in tokenized]\n",
    "    pcnt = 0\n",
    "    \n",
    "    # check for membership in negative words list, making sure 'not' doesn't precede\n",
    "    for word in tokenized:\n",
    "        if tokenized.index(word) == 0 and word in negative:\n",
    "            pcnt += 1/len(tokenized)\n",
    "        elif tokenized.index(word) == 1:\n",
    "            if word in negative and (tokenized[tokenized.index(word)-1] != 'not'):\n",
    "                pcnt += 1/len(tokenized)\n",
    "        elif tokenized.index(word) > 1:\n",
    "            if word in negative and (tokenized[tokenized.index(word)-1] != 'not') and (tokenized[tokenized.index(word)-2] != 'not'):\n",
    "                pcnt += 1/len(tokenized)\n",
    "    return pcnt\n",
    "\n",
    "# Apply percent_positive to the text column in our dataframe\n",
    "amazon['positive'] = amazon['text'].apply(percent_positive)\n",
    "\n",
    "# Apply percent_negative to the text column in our dataframe\n",
    "amazon['negative'] = amazon['text'].apply(percent_negative)\n",
    "\n",
    "# Load the Yelp dataset\n",
    "yelp = pd.read_csv(r'yelp_labelled.txt', delimiter= '\\t', header=None)\n",
    "yelp.columns = ['text', 'sentiment']\n",
    "yelp.head()\n",
    "\n",
    "# Apply percent_positive to the text column in our dataframe\n",
    "yelp['positive'] = yelp['text'].apply(percent_positive)\n",
    "\n",
    "# Apply percent_negative to the text column in our dataframe\n",
    "yelp['negative'] = yelp['text'].apply(percent_negative)\n",
    "\n",
    "yelp.head()\n",
    "\n",
    "# Initialize a model object\n",
    "classifier = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "classifier.fit(amazon[['positive','negative']], amazon['sentiment'])\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = classifier.predict(yelp[['positive','negative']])\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    yelp.shape[0],\n",
    "    (yelp['sentiment'] != y_pred).sum()\n",
    "))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  positive  \\\n",
       "0  So there is no way for me to plug it in here i...          0      0.00   \n",
       "1                        Good case, Excellent value.          1      0.50   \n",
       "2                             Great for the jawbone.          1      0.25   \n",
       "3  Tied to charger for conversations lasting more...          0      0.00   \n",
       "4                                  The mic is great.          1      0.25   \n",
       "\n",
       "   negative  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.090909  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  positive  \\\n",
       "0                           Wow... Loved this place.          1  0.500000   \n",
       "1                                 Crust is not good.          0  0.000000   \n",
       "2          Not tasty and the texture was just nasty.          0  0.000000   \n",
       "3  Stopped by during the late May bank holiday of...          1  0.133333   \n",
       "4  The selection on the menu was great and so wer...          1  0.083333   \n",
       "\n",
       "   negative  \n",
       "0     0.000  \n",
       "1     0.000  \n",
       "2     0.125  \n",
       "3     0.000  \n",
       "4     0.000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 488\n"
     ]
    }
   ],
   "source": [
    "amazon2 = amazon.copy()\n",
    "yelp2 = yelp.copy()\n",
    "keywords = positive+negative+stop\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    amazon2[str(key)] = amazon2.text.str.contains(str(key),case=False)\n",
    "    yelp2[str(key)] = yelp2.text.str.contains(str(key),case=False)\n",
    "    \n",
    "# Initialize a model object\n",
    "classifier = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "classifier.fit(amazon2[[i for i in amazon2.columns if i not in ['text','sentiment']]], amazon2['sentiment'])\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = classifier.predict(amazon2[[i for i in amazon2.columns if i not in ['text','sentiment']]])\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    yelp.shape[0],\n",
    "    (yelp['sentiment'] != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took quite some time to load about 7000 columns into a dataframe. although we have kept the positive and negative columns, the accuracy went down. Let's take a look at the features more closely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pythonML0\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Get rid of categorical columns\n",
    "amazon2_pca = amazon2[[i for i in amazon2.columns if i not in ['text','sentiment']]]\n",
    "\n",
    "# Convert bool to binary numerical\n",
    "def mapVals(val):\n",
    "    if str(val)=='True':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "for col in amazon2_pca.columns:\n",
    "    amazon2_pca[col] = amazon2_pca[col].apply(mapVals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pythonML0\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Anaconda3\\envs\\pythonML0\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# PCA \n",
    "X = StandardScaler().fit_transform(amazon2_pca)\n",
    "sklearn_pca = PCA(n_components=10,svd_solver='full')\n",
    "Y_sklearn = sklearn_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame({'target':amazon['sentiment']})\n",
    "\n",
    "for i in range(1,11):\n",
    "    pca_df['pca{}'.format(i)] = Y_sklearn[:,i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>pca9</th>\n",
       "      <th>pca10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.106893e-02</td>\n",
       "      <td>-2.385460e-02</td>\n",
       "      <td>3.199387e-02</td>\n",
       "      <td>4.827053e-02</td>\n",
       "      <td>-6.172985e-02</td>\n",
       "      <td>3.772506e-02</td>\n",
       "      <td>5.922058e-02</td>\n",
       "      <td>5.508795e-02</td>\n",
       "      <td>-3.228601e-02</td>\n",
       "      <td>-2.110798e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca7</th>\n",
       "      <td>0.059221</td>\n",
       "      <td>-6.409783e-17</td>\n",
       "      <td>-5.215385e-17</td>\n",
       "      <td>2.614631e-16</td>\n",
       "      <td>-1.139876e-16</td>\n",
       "      <td>-7.493917e-17</td>\n",
       "      <td>-2.038653e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.256411e-16</td>\n",
       "      <td>4.258721e-17</td>\n",
       "      <td>-2.440636e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca8</th>\n",
       "      <td>0.055088</td>\n",
       "      <td>3.397882e-16</td>\n",
       "      <td>-2.047047e-16</td>\n",
       "      <td>5.916474e-16</td>\n",
       "      <td>4.503321e-17</td>\n",
       "      <td>-4.838666e-16</td>\n",
       "      <td>1.208278e-16</td>\n",
       "      <td>4.256411e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.508837e-16</td>\n",
       "      <td>-1.511894e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca4</th>\n",
       "      <td>0.048271</td>\n",
       "      <td>5.791732e-18</td>\n",
       "      <td>-1.933894e-17</td>\n",
       "      <td>-2.054222e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.271407e-17</td>\n",
       "      <td>-8.623413e-17</td>\n",
       "      <td>-1.139876e-16</td>\n",
       "      <td>4.503321e-17</td>\n",
       "      <td>3.984172e-17</td>\n",
       "      <td>-9.987099e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca6</th>\n",
       "      <td>0.037725</td>\n",
       "      <td>-2.235223e-17</td>\n",
       "      <td>2.575044e-17</td>\n",
       "      <td>-4.742253e-17</td>\n",
       "      <td>-8.623413e-17</td>\n",
       "      <td>3.648804e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.038653e-16</td>\n",
       "      <td>1.208278e-16</td>\n",
       "      <td>-1.069905e-16</td>\n",
       "      <td>2.125987e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca3</th>\n",
       "      <td>0.031994</td>\n",
       "      <td>7.770912e-17</td>\n",
       "      <td>3.278689e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.054222e-16</td>\n",
       "      <td>-1.460058e-17</td>\n",
       "      <td>-4.742253e-17</td>\n",
       "      <td>2.614631e-16</td>\n",
       "      <td>5.916474e-16</td>\n",
       "      <td>1.045243e-16</td>\n",
       "      <td>3.087695e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca10</th>\n",
       "      <td>-0.021108</td>\n",
       "      <td>5.856695e-17</td>\n",
       "      <td>-2.225898e-17</td>\n",
       "      <td>3.087695e-17</td>\n",
       "      <td>-9.987099e-18</td>\n",
       "      <td>-3.963376e-16</td>\n",
       "      <td>2.125987e-18</td>\n",
       "      <td>-2.440636e-16</td>\n",
       "      <td>-1.511894e-17</td>\n",
       "      <td>-3.505914e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca2</th>\n",
       "      <td>-0.023855</td>\n",
       "      <td>-1.907503e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.278689e-17</td>\n",
       "      <td>-1.933894e-17</td>\n",
       "      <td>3.826220e-17</td>\n",
       "      <td>2.575044e-17</td>\n",
       "      <td>-5.215385e-17</td>\n",
       "      <td>-2.047047e-16</td>\n",
       "      <td>-2.102925e-17</td>\n",
       "      <td>-2.225898e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca9</th>\n",
       "      <td>-0.032286</td>\n",
       "      <td>7.956466e-17</td>\n",
       "      <td>-2.102925e-17</td>\n",
       "      <td>1.045243e-16</td>\n",
       "      <td>3.984172e-17</td>\n",
       "      <td>2.204879e-17</td>\n",
       "      <td>-1.069905e-16</td>\n",
       "      <td>4.258721e-17</td>\n",
       "      <td>-1.508837e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.505914e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca5</th>\n",
       "      <td>-0.061730</td>\n",
       "      <td>-3.171678e-17</td>\n",
       "      <td>3.826220e-17</td>\n",
       "      <td>-1.460058e-17</td>\n",
       "      <td>5.271407e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.648804e-16</td>\n",
       "      <td>-7.493917e-17</td>\n",
       "      <td>-4.838666e-16</td>\n",
       "      <td>2.204879e-17</td>\n",
       "      <td>-3.963376e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca1</th>\n",
       "      <td>-0.081069</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.907503e-16</td>\n",
       "      <td>7.770912e-17</td>\n",
       "      <td>5.791732e-18</td>\n",
       "      <td>-3.171678e-17</td>\n",
       "      <td>-2.235223e-17</td>\n",
       "      <td>-6.409783e-17</td>\n",
       "      <td>3.397882e-16</td>\n",
       "      <td>7.956466e-17</td>\n",
       "      <td>5.856695e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target          pca1          pca2          pca3          pca4  \\\n",
       "target  1.000000 -8.106893e-02 -2.385460e-02  3.199387e-02  4.827053e-02   \n",
       "pca7    0.059221 -6.409783e-17 -5.215385e-17  2.614631e-16 -1.139876e-16   \n",
       "pca8    0.055088  3.397882e-16 -2.047047e-16  5.916474e-16  4.503321e-17   \n",
       "pca4    0.048271  5.791732e-18 -1.933894e-17 -2.054222e-16  1.000000e+00   \n",
       "pca6    0.037725 -2.235223e-17  2.575044e-17 -4.742253e-17 -8.623413e-17   \n",
       "pca3    0.031994  7.770912e-17  3.278689e-17  1.000000e+00 -2.054222e-16   \n",
       "pca10  -0.021108  5.856695e-17 -2.225898e-17  3.087695e-17 -9.987099e-18   \n",
       "pca2   -0.023855 -1.907503e-16  1.000000e+00  3.278689e-17 -1.933894e-17   \n",
       "pca9   -0.032286  7.956466e-17 -2.102925e-17  1.045243e-16  3.984172e-17   \n",
       "pca5   -0.061730 -3.171678e-17  3.826220e-17 -1.460058e-17  5.271407e-17   \n",
       "pca1   -0.081069  1.000000e+00 -1.907503e-16  7.770912e-17  5.791732e-18   \n",
       "\n",
       "                pca5          pca6          pca7          pca8          pca9  \\\n",
       "target -6.172985e-02  3.772506e-02  5.922058e-02  5.508795e-02 -3.228601e-02   \n",
       "pca7   -7.493917e-17 -2.038653e-16  1.000000e+00  4.256411e-16  4.258721e-17   \n",
       "pca8   -4.838666e-16  1.208278e-16  4.256411e-16  1.000000e+00 -1.508837e-16   \n",
       "pca4    5.271407e-17 -8.623413e-17 -1.139876e-16  4.503321e-17  3.984172e-17   \n",
       "pca6    3.648804e-16  1.000000e+00 -2.038653e-16  1.208278e-16 -1.069905e-16   \n",
       "pca3   -1.460058e-17 -4.742253e-17  2.614631e-16  5.916474e-16  1.045243e-16   \n",
       "pca10  -3.963376e-16  2.125987e-18 -2.440636e-16 -1.511894e-17 -3.505914e-16   \n",
       "pca2    3.826220e-17  2.575044e-17 -5.215385e-17 -2.047047e-16 -2.102925e-17   \n",
       "pca9    2.204879e-17 -1.069905e-16  4.258721e-17 -1.508837e-16  1.000000e+00   \n",
       "pca5    1.000000e+00  3.648804e-16 -7.493917e-17 -4.838666e-16  2.204879e-17   \n",
       "pca1   -3.171678e-17 -2.235223e-17 -6.409783e-17  3.397882e-16  7.956466e-17   \n",
       "\n",
       "               pca10  \n",
       "target -2.110798e-02  \n",
       "pca7   -2.440636e-16  \n",
       "pca8   -1.511894e-17  \n",
       "pca4   -9.987099e-18  \n",
       "pca6    2.125987e-18  \n",
       "pca3    3.087695e-17  \n",
       "pca10   1.000000e+00  \n",
       "pca2   -2.225898e-17  \n",
       "pca9   -3.505914e-16  \n",
       "pca5   -3.963376e-16  \n",
       "pca1    5.856695e-17  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df.corr().sort_values(by=['target'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 496\n"
     ]
    }
   ],
   "source": [
    "#repeat classification with new df\n",
    "\n",
    "# Fit our model to the data.\n",
    "classifier.fit(pca_df[[i for i in pca_df.columns if i != 'target']], pca_df['target'])\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = classifier.predict(pca_df[[i for i in pca_df.columns if i != 'target']])\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    yelp.shape[0],\n",
    "    (yelp['sentiment'] != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did not help. Would it if we limit PCA components to 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pythonML0\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Anaconda3\\envs\\pythonML0\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# # PCA \n",
    "X = StandardScaler().fit_transform(amazon2_pca)\n",
    "sklearn_pca = PCA(n_components=2,svd_solver='full')\n",
    "Y_sklearn = sklearn_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.377261</td>\n",
       "      <td>-1.619570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.279472</td>\n",
       "      <td>1.721639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.204156</td>\n",
       "      <td>0.817193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.297146</td>\n",
       "      <td>-1.067836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.415590</td>\n",
       "      <td>0.659020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target      pca1      pca2\n",
       "0       0  2.377261 -1.619570\n",
       "1       1 -3.279472  1.721639\n",
       "2       1 -1.204156  0.817193\n",
       "3       0  1.297146 -1.067836\n",
       "4       1 -1.415590  0.659020"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df = pd.DataFrame({'target':amazon['sentiment']})\n",
    "\n",
    "for i in range(1,3):\n",
    "    pca_df['pca{}'.format(i)] = Y_sklearn[:,i-1]\n",
    "    \n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 533\n"
     ]
    }
   ],
   "source": [
    "#repeat classification with new df\n",
    "\n",
    "# Fit our model to the data.\n",
    "classifier.fit(pca_df[[i for i in pca_df.columns if i != 'target']], pca_df['target'])\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = classifier.predict(pca_df[[i for i in pca_df.columns if i != 'target']])\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    yelp.shape[0],\n",
    "    (yelp['sentiment'] != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the model is becoming worse as proceed in feature engineering. This may be due to the original features (word columns) not being fit as features for prediction, especially with their large number. What if we create a simple positivity score calculated from words in a sentence being a positive/negative word list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\pythonML0\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\envs\\pythonML0\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment      perc\n",
       "0                           Wow... Loved this place.          1  0.000000\n",
       "1                                 Crust is not good.          0  0.000000\n",
       "2          Not tasty and the texture was just nasty.          0  0.000000\n",
       "3  Stopped by during the late May bank holiday of...          1  0.133333\n",
       "4  The selection on the menu was great and so wer...          1  0.083333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_perc(review):\n",
    "    perc = 0\n",
    "    for word in review.split(' '):\n",
    "        if word in positive:\n",
    "            perc += 1/len(review.split(' '))\n",
    "        elif word in negative:\n",
    "            perc -= 1/len(review.split(' '))\n",
    "    return perc\n",
    "\n",
    "# remove the original positive and negative columns\n",
    "amazon_5 = amazon[['text','sentiment']]\n",
    "yelp_5 = yelp[['text','sentiment']]\n",
    "\n",
    "# Calculate percentage of word membership in pos & neg lists\n",
    "amazon_5['perc'] = amazon_5['text'].apply(cal_perc)\n",
    "yelp_5['perc'] = yelp_5['text'].apply(cal_perc)\n",
    "yelp_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 321\n"
     ]
    }
   ],
   "source": [
    "# Initialize a model object\n",
    "classifier = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "classifier.fit(amazon_5[['perc']], amazon_5['sentiment'])\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = classifier.predict(yelp_5[['perc']])\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    yelp.shape[0],\n",
    "    (yelp['sentiment'] != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do any of your classifiers seem to overfit?\n",
    "\n",
    "Yes, I did not implement the function to count for words like \"not\" and \"not so\" counting before a positive and negative word. The models had learned from each of the 7000 words being in columns that the word's existence in the sentence means positive or negative, which is not true.\n",
    "\n",
    "Which seem to perform the best? Why?\n",
    "\n",
    "The final model had higher accuracy with only 1 feature compared to models with thousands of features. This may be due to the other models learning from the noise caused by unnecessary data. I believe the last model encompasses the negativity and positivity of a sentence better than the others, having understood the real sentiment better than having many columns do the same job.\n",
    "\n",
    "\n",
    "Which features seemed to be most impactful to performance?\n",
    "\n",
    "They were the features where positivity and negativity was calculated or *engineered* to show one value that describes these measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
